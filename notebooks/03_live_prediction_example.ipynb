{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Live Prediction Example\n",
    "\n",
    "This notebook demonstrates the end-to-end prediction pipeline using **real production data**:\n",
    "\n",
    "1. **Load models** - Production LightGBM models from `saved_xl/`\n",
    "2. **Load real prediction** - Actual pick from production files\n",
    "3. **Examine model architecture** - Understand the two-head stacked design\n",
    "4. **Validate against outcome** - Check if the pick won using real game data\n",
    "\n",
    "**All data in this notebook is REAL** - loaded from production files and database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import date, datetime\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path(\"../\").resolve()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Load Production Models\n",
    "\n",
    "Our models are stored as pickle files with associated metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = PROJECT_ROOT / \"nba\" / \"models\" / \"saved_xl\"\n",
    "\n",
    "def load_market_model(market: str):\n",
    "    \"\"\"Load all components for a market model.\"\"\"\n",
    "    prefix = MODELS_DIR / f\"{market}_market\"\n",
    "    \n",
    "    components = {}\n",
    "    \n",
    "    # Load model files\n",
    "    with open(f\"{prefix}_regressor.pkl\", \"rb\") as f:\n",
    "        components['regressor'] = pickle.load(f)\n",
    "    \n",
    "    with open(f\"{prefix}_classifier.pkl\", \"rb\") as f:\n",
    "        components['classifier'] = pickle.load(f)\n",
    "    \n",
    "    with open(f\"{prefix}_calibrator.pkl\", \"rb\") as f:\n",
    "        components['calibrator'] = pickle.load(f)\n",
    "    \n",
    "    with open(f\"{prefix}_imputer.pkl\", \"rb\") as f:\n",
    "        components['imputer'] = pickle.load(f)\n",
    "    \n",
    "    with open(f\"{prefix}_scaler.pkl\", \"rb\") as f:\n",
    "        components['scaler'] = pickle.load(f)\n",
    "    \n",
    "    with open(f\"{prefix}_features.pkl\", \"rb\") as f:\n",
    "        components['features'] = pickle.load(f)\n",
    "    \n",
    "    with open(f\"{prefix}_metadata.json\", \"r\") as f:\n",
    "        components['metadata'] = json.load(f)\n",
    "    \n",
    "    return components\n",
    "\n",
    "# Load POINTS model\n",
    "points_model = load_market_model('points')\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Market: {points_model['metadata']['market']}\")\n",
    "print(f\"Features: {len(points_model['features'])}\")\n",
    "print(f\"Trained: {points_model['metadata']['trained_date']}\")\n",
    "print(f\"Architecture: {points_model['metadata']['architecture']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Model Architecture Overview\n",
    "\n",
    "Our system uses a **two-head stacked architecture**:\n",
    "- **Head 1 (Regressor)**: Predicts the actual stat value\n",
    "- **Head 2 (Classifier)**: Predicts P(OVER) using regressor output as additional feature\n",
    "- **Calibration**: Isotonic regression for probability calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model metrics from metadata\n",
    "metadata = points_model['metadata']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"MODEL ARCHITECTURE: {metadata['market']}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n--- Regressor Metrics ---\")\n",
    "reg_metrics = metadata.get('metrics', {}).get('regressor', {})\n",
    "for key, val in reg_metrics.items():\n",
    "    print(f\"  {key}: {val}\")\n",
    "\n",
    "print(f\"\\n--- Classifier Metrics ---\")\n",
    "clf_metrics = metadata.get('metrics', {}).get('classifier', {})\n",
    "for key, val in clf_metrics.items():\n",
    "    print(f\"  {key}: {val}\")\n",
    "\n",
    "print(f\"\\n--- Blend Config ---\")\n",
    "blend = metadata.get('blend_config', {})\n",
    "for key, val in blend.items():\n",
    "    print(f\"  {key}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature categories\n",
    "features = points_model['features']\n",
    "\n",
    "def categorize_feature(name):\n",
    "    if name.startswith('ema_') or name.startswith('fg_pct') or name.startswith('ft_rate'):\n",
    "        return 'Player Rolling Stats'\n",
    "    elif name.startswith('h2h_'):\n",
    "        return 'Head-to-Head'\n",
    "    elif name.startswith('prop_'):\n",
    "        return 'Prop History'\n",
    "    elif name.startswith('bp_'):\n",
    "        return 'BettingPros Data'\n",
    "    elif name.startswith('vegas_'):\n",
    "        return 'Vegas Lines'\n",
    "    elif 'deviation' in name or 'line' in name.lower() or 'book' in name:\n",
    "        return 'Book Disagreement'\n",
    "    elif 'team' in name or 'opp' in name or 'pace' in name:\n",
    "        return 'Team Context'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "categories = {}\n",
    "for f in features:\n",
    "    cat = categorize_feature(f)\n",
    "    categories[cat] = categories.get(cat, 0) + 1\n",
    "\n",
    "print(f\"\\n--- Feature Categories ({len(features)} total) ---\")\n",
    "for cat, count in sorted(categories.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {cat}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Load Real Production Pick\n",
    "\n",
    "Load an actual pick from our production prediction files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS_DIR = PROJECT_ROOT / \"nba\" / \"betting_xl\" / \"predictions\"\n",
    "\n",
    "# Find a recent prediction file with POINTS picks\n",
    "def find_points_pick():\n",
    "    \"\"\"Find a real POINTS pick from production files.\"\"\"\n",
    "    for f in sorted(PREDICTIONS_DIR.glob(\"*.json\"), reverse=True):\n",
    "        try:\n",
    "            with open(f) as fp:\n",
    "                data = json.load(fp)\n",
    "                for pick in data.get(\"picks\", []):\n",
    "                    if pick.get(\"stat_type\") == \"POINTS\":\n",
    "                        pick['game_date'] = data.get('date', f.stem.split('_')[-1])\n",
    "                        pick['source_file'] = f.name\n",
    "                        return pick\n",
    "        except:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "real_pick = find_points_pick()\n",
    "\n",
    "if real_pick:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"REAL PRODUCTION PICK\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nSource: {real_pick['source_file']}\")\n",
    "    print(f\"Date: {real_pick['game_date']}\")\n",
    "    print(f\"\\nPlayer: {real_pick['player_name']}\")\n",
    "    print(f\"Market: {real_pick['stat_type']}\")\n",
    "    print(f\"Side: {real_pick.get('side', 'OVER')}\")\n",
    "    print(f\"Line: {real_pick.get('line', real_pick.get('best_line'))}\")\n",
    "    print(f\"Projection: {real_pick.get('projection', 'N/A')}\")\n",
    "    print(f\"Probability: {real_pick.get('probability', 'N/A')}\")\n",
    "    print(f\"Confidence: {real_pick.get('confidence', 'N/A')}\")\n",
    "    \n",
    "    if 'reasoning' in real_pick:\n",
    "        print(f\"\\nReasoning: {real_pick['reasoning']}\")\n",
    "else:\n",
    "    print(\"No POINTS picks found in prediction files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Validate Against Actual Outcome\n",
    "\n",
    "Query the database to see how this pick actually performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5536,\n",
    "    \"user\": \"nba_user\",\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"database\": \"nba_players\",\n",
    "}\n",
    "\n",
    "def get_actual_result(player_name: str, game_date: str, stat_type: str):\n",
    "    \"\"\"Fetch actual result from database.\"\"\"\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Map stat type to column\n",
    "    stat_column = {\n",
    "        'POINTS': 'points',\n",
    "        'REBOUNDS': 'rebounds',\n",
    "        'ASSISTS': 'assists',\n",
    "        'THREES': 'three_pointers_made'\n",
    "    }.get(stat_type, 'points')\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT l.{stat_column}, l.minutes, p.full_name\n",
    "        FROM player_game_logs l\n",
    "        JOIN player_profile p ON l.player_id = p.player_id\n",
    "        WHERE p.full_name ILIKE %s\n",
    "        AND l.game_date = %s\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(query, (f\"%{player_name}%\", game_date))\n",
    "    result = cursor.fetchone()\n",
    "    \n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return result\n",
    "\n",
    "if real_pick:\n",
    "    result = get_actual_result(\n",
    "        real_pick['player_name'],\n",
    "        real_pick['game_date'],\n",
    "        real_pick['stat_type']\n",
    "    )\n",
    "    \n",
    "    if result:\n",
    "        actual_value, minutes, matched_name = result\n",
    "        line = real_pick.get('line', real_pick.get('best_line'))\n",
    "        side = real_pick.get('side', 'OVER')\n",
    "        \n",
    "        # Determine outcome\n",
    "        if side == 'OVER':\n",
    "            won = actual_value > line\n",
    "        else:\n",
    "            won = actual_value < line\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"VALIDATION RESULT\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"\\nPlayer: {matched_name}\")\n",
    "        print(f\"Date: {real_pick['game_date']}\")\n",
    "        print(f\"Minutes: {minutes}\")\n",
    "        print(f\"\\nPick: {side} {line}\")\n",
    "        print(f\"Actual: {actual_value}\")\n",
    "        print(f\"Difference: {actual_value - line:+.1f}\")\n",
    "        print(f\"\\nOutcome: {'WIN' if won else 'LOSS'}\")\n",
    "        print(f\"Profit: {'+0.91' if won else '-1.00'} units\")\n",
    "    else:\n",
    "        print(f\"\\nNo game log found for {real_pick['player_name']} on {real_pick['game_date']}\")\n",
    "        print(\"(Player may have been injured, DNP, or game not yet played)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if real_pick and result:\n",
    "    actual_value, minutes, _ = result\n",
    "    line = real_pick.get('line', real_pick.get('best_line'))\n",
    "    projection = real_pick.get('projection', line)\n",
    "    prob = real_pick.get('probability', 0.5)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Left: Prediction vs Actual\n",
    "    ax1 = axes[0]\n",
    "    categories = ['Line', 'Projection', 'Actual']\n",
    "    values = [line, projection, actual_value]\n",
    "    colors = ['#3498db', '#9b59b6', '#2ecc71' if actual_value > line else '#e74c3c']\n",
    "    \n",
    "    bars = ax1.bar(categories, values, color=colors, edgecolor='black', width=0.6)\n",
    "    ax1.axhline(y=line, color='red', linestyle='--', alpha=0.7, label=f'Line ({line})')\n",
    "    ax1.set_ylabel(f'{real_pick[\"stat_type\"]}')\n",
    "    ax1.set_title(f'{real_pick[\"player_name\"]} - {real_pick[\"game_date\"]}')\n",
    "    ax1.legend()\n",
    "    \n",
    "    for bar, val in zip(bars, values):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, \n",
    "                 f'{val:.1f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Right: Probability gauge\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    # Simple bar representation of probability\n",
    "    ax2.barh(['P(OVER)'], [prob * 100], color='#3498db', height=0.4)\n",
    "    ax2.barh(['P(UNDER)'], [(1-prob) * 100], color='#e74c3c', height=0.4)\n",
    "    ax2.axvline(x=52.4, color='black', linestyle='--', label='Breakeven (52.4%)')\n",
    "    ax2.set_xlim(0, 100)\n",
    "    ax2.set_xlabel('Probability (%)')\n",
    "    ax2.set_title('Model Confidence')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Add text\n",
    "    ax2.text(prob * 100 / 2, 0, f'{prob*100:.1f}%', ha='center', va='center', \n",
    "             fontsize=14, fontweight='bold', color='white')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prediction_example.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Examine Full Pick JSON\n",
    "\n",
    "This is the actual JSON output from our production system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if real_pick:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"FULL PICK JSON (Real Production Output)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(json.dumps(real_pick, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "This notebook demonstrated the complete prediction pipeline with **real data**:\n",
    "\n",
    "1. **Model Loading** - 166 features, two-head LightGBM architecture from `saved_xl/`\n",
    "2. **Real Pick** - Actual production pick from `predictions/` directory\n",
    "3. **Validation** - Outcome verified against PostgreSQL database\n",
    "\n",
    "**In Production:**\n",
    "- Features are extracted from 4 PostgreSQL databases in real-time\n",
    "- Props are fetched from 7 sportsbooks via BettingPros API\n",
    "- Picks are generated twice daily (morning refresh, evening predictions)\n",
    "- Results are tracked and validated automatically\n",
    "\n",
    "**All data shown is REAL** - no synthetic or simulated data was used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
