{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Live Prediction Example\n\nThis notebook demonstrates the end-to-end prediction pipeline using **real production data**:\n\n1. **Load models** - Production LightGBM models from `saved_xl/` (XL: 102 features, V3: 136 features)\n2. **Load real prediction** - Actual pick from production files\n3. **Examine model architecture** - Understand the two-head stacked design\n4. **Validate against outcome** - Check if the pick won using real game data\n\n**All data in this notebook is REAL** - loaded from production files and database.\n\n**Model Versions:**\n- **XL** (102 features): Original model trained Dec 2025\n- **V3** (136 features): Enhanced model with temporal decay, volatility, H2H decay features (Feb 2026)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import date, datetime\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path(\"../\").resolve()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Load Production Models\n",
    "\n",
    "Our models are stored as pickle files with associated metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "MODELS_DIR = PROJECT_ROOT / \"nba\" / \"models\" / \"saved_xl\"\n\ndef load_market_model(market: str, version: str = \"xl\"):\n    \"\"\"Load all components for a market model.\n    \n    Args:\n        market: 'points' or 'rebounds'\n        version: 'xl' (102 features) or 'v3' (136 features)\n    \"\"\"\n    prefix = MODELS_DIR / f\"{market}_{version}\"\n    \n    components = {}\n    \n    # Load model files\n    with open(f\"{prefix}_regressor.pkl\", \"rb\") as f:\n        components['regressor'] = pickle.load(f)\n    \n    with open(f\"{prefix}_classifier.pkl\", \"rb\") as f:\n        components['classifier'] = pickle.load(f)\n    \n    with open(f\"{prefix}_calibrator.pkl\", \"rb\") as f:\n        components['calibrator'] = pickle.load(f)\n    \n    with open(f\"{prefix}_imputer.pkl\", \"rb\") as f:\n        components['imputer'] = pickle.load(f)\n    \n    with open(f\"{prefix}_scaler.pkl\", \"rb\") as f:\n        components['scaler'] = pickle.load(f)\n    \n    with open(f\"{prefix}_features.pkl\", \"rb\") as f:\n        components['features'] = pickle.load(f)\n    \n    with open(f\"{prefix}_metadata.json\", \"r\") as f:\n        components['metadata'] = json.load(f)\n    \n    return components\n\n# Load both XL and V3 POINTS models\npoints_xl = load_market_model('points', 'xl')\npoints_v3 = load_market_model('points', 'v3')\n\nprint(\"Models loaded successfully!\")\nprint(f\"\\n--- XL Model ---\")\nprint(f\"Market: {points_xl['metadata']['market']}\")\nprint(f\"Features: {len(points_xl['features'])}\")\nprint(f\"Trained: {points_xl['metadata']['trained_date']}\")\n\nprint(f\"\\n--- V3 Model ---\")\nprint(f\"Market: {points_v3['metadata']['market']}\")\nprint(f\"Features: {len(points_v3['features'])}\")\nprint(f\"Trained: {points_v3['metadata']['trained_date']}\")\nprint(f\"Architecture: {points_v3['metadata']['architecture']}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": "## 2. Model Architecture Overview\n\nOur system uses a **two-head stacked architecture** with **dual model versions**:\n\n**XL Model (102 features):**\n- 78 player features (rolling stats, team context, matchup history)\n- 20 book disagreement features (line spread, deviations, accuracy)\n- 4 computed features (is_home, line, opponent_team, expected_diff)\n\n**V3 Model (136 features = XL + 34 new):**\n- All 102 XL features, plus:\n- 6 temporal features (days_into_season, season_phase, is_early/mid/late/playoffs)\n- 8 volatility features (stat std L5/L10, trend ratios, usage_volatility_score)\n- 5 H2H decay features (decayed averages with tau=45 days, reliability)\n- 9 line/book features (consensus_strength, snapshot tracking)\n- 6 matchup features (opp_def_factor, efficiency_vs_context, game_velocity)\n\n**Pipeline:**\n- **Head 1 (Regressor)**: Predicts the actual stat value\n- **Head 2 (Classifier)**: Predicts P(OVER) using regressor output as additional feature\n- **Calibration**: Isotonic regression for probability calibration\n\n**In Production:** Both XL and V3 run in parallel, generating independent picks."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# Display model metrics from metadata - compare XL vs V3\nprint(\"=\" * 70)\nprint(\"MODEL COMPARISON: XL (102 features) vs V3 (136 features)\")\nprint(\"=\" * 70)\n\nfor name, model in [(\"XL\", points_xl), (\"V3\", points_v3)]:\n    metadata = model['metadata']\n    print(f\"\\n{'='*30} {name} {'='*30}\")\n    \n    print(f\"\\n--- Regressor Metrics ---\")\n    reg_metrics = metadata.get('metrics', {}).get('regressor', {})\n    for key, val in reg_metrics.items():\n        print(f\"  {key}: {val:.4f}\" if isinstance(val, float) else f\"  {key}: {val}\")\n\n    print(f\"\\n--- Classifier Metrics ---\")\n    clf_metrics = metadata.get('metrics', {}).get('classifier', {})\n    for key, val in clf_metrics.items():\n        print(f\"  {key}: {val:.4f}\" if isinstance(val, float) else f\"  {key}: {val}\")\n\nprint(f\"\\n--- Blend Config (same for both) ---\")\nblend = points_v3['metadata'].get('blend_config', {})\nfor key, val in blend.items():\n    print(f\"  {key}: {val}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature categories\n",
    "features = points_model['features']\n",
    "\n",
    "def categorize_feature(name):\n",
    "    if name.startswith('ema_') or name.startswith('fg_pct') or name.startswith('ft_rate'):\n",
    "        return 'Player Rolling Stats'\n",
    "    elif name.startswith('h2h_'):\n",
    "        return 'Head-to-Head'\n",
    "    elif name.startswith('prop_'):\n",
    "        return 'Prop History'\n",
    "    elif name.startswith('bp_'):\n",
    "        return 'BettingPros Data'\n",
    "    elif name.startswith('vegas_'):\n",
    "        return 'Vegas Lines'\n",
    "    elif 'deviation' in name or 'line' in name.lower() or 'book' in name:\n",
    "        return 'Book Disagreement'\n",
    "    elif 'team' in name or 'opp' in name or 'pace' in name:\n",
    "        return 'Team Context'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "categories = {}\n",
    "for f in features:\n",
    "    cat = categorize_feature(f)\n",
    "    categories[cat] = categories.get(cat, 0) + 1\n",
    "\n",
    "print(f\"\\n--- Feature Categories ({len(features)} total) ---\")\n",
    "for cat, count in sorted(categories.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {cat}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Load Real Production Pick\n",
    "\n",
    "Load an actual pick from our production prediction files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS_DIR = PROJECT_ROOT / \"nba\" / \"betting_xl\" / \"predictions\"\n",
    "\n",
    "# Find a recent prediction file with POINTS picks\n",
    "def find_points_pick():\n",
    "    \"\"\"Find a real POINTS pick from production files.\"\"\"\n",
    "    for f in sorted(PREDICTIONS_DIR.glob(\"*.json\"), reverse=True):\n",
    "        try:\n",
    "            with open(f) as fp:\n",
    "                data = json.load(fp)\n",
    "                for pick in data.get(\"picks\", []):\n",
    "                    if pick.get(\"stat_type\") == \"POINTS\":\n",
    "                        pick['game_date'] = data.get('date', f.stem.split('_')[-1])\n",
    "                        pick['source_file'] = f.name\n",
    "                        return pick\n",
    "        except:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "real_pick = find_points_pick()\n",
    "\n",
    "if real_pick:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"REAL PRODUCTION PICK\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nSource: {real_pick['source_file']}\")\n",
    "    print(f\"Date: {real_pick['game_date']}\")\n",
    "    print(f\"\\nPlayer: {real_pick['player_name']}\")\n",
    "    print(f\"Market: {real_pick['stat_type']}\")\n",
    "    print(f\"Side: {real_pick.get('side', 'OVER')}\")\n",
    "    print(f\"Line: {real_pick.get('line', real_pick.get('best_line'))}\")\n",
    "    print(f\"Projection: {real_pick.get('projection', 'N/A')}\")\n",
    "    print(f\"Probability: {real_pick.get('probability', 'N/A')}\")\n",
    "    print(f\"Confidence: {real_pick.get('confidence', 'N/A')}\")\n",
    "    \n",
    "    if 'reasoning' in real_pick:\n",
    "        print(f\"\\nReasoning: {real_pick['reasoning']}\")\n",
    "else:\n",
    "    print(\"No POINTS picks found in prediction files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Validate Against Actual Outcome\n",
    "\n",
    "Query the database to see how this pick actually performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5536,\n",
    "    \"user\": \"nba_user\",\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"database\": \"nba_players\",\n",
    "}\n",
    "\n",
    "def get_actual_result(player_name: str, game_date: str, stat_type: str):\n",
    "    \"\"\"Fetch actual result from database.\"\"\"\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Map stat type to column\n",
    "    stat_column = {\n",
    "        'POINTS': 'points',\n",
    "        'REBOUNDS': 'rebounds',\n",
    "        'ASSISTS': 'assists',\n",
    "        'THREES': 'three_pointers_made'\n",
    "    }.get(stat_type, 'points')\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        SELECT l.{stat_column}, l.minutes, p.full_name\n",
    "        FROM player_game_logs l\n",
    "        JOIN player_profile p ON l.player_id = p.player_id\n",
    "        WHERE p.full_name ILIKE %s\n",
    "        AND l.game_date = %s\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(query, (f\"%{player_name}%\", game_date))\n",
    "    result = cursor.fetchone()\n",
    "    \n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return result\n",
    "\n",
    "if real_pick:\n",
    "    result = get_actual_result(\n",
    "        real_pick['player_name'],\n",
    "        real_pick['game_date'],\n",
    "        real_pick['stat_type']\n",
    "    )\n",
    "    \n",
    "    if result:\n",
    "        actual_value, minutes, matched_name = result\n",
    "        line = real_pick.get('line', real_pick.get('best_line'))\n",
    "        side = real_pick.get('side', 'OVER')\n",
    "        \n",
    "        # Determine outcome\n",
    "        if side == 'OVER':\n",
    "            won = actual_value > line\n",
    "        else:\n",
    "            won = actual_value < line\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"VALIDATION RESULT\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"\\nPlayer: {matched_name}\")\n",
    "        print(f\"Date: {real_pick['game_date']}\")\n",
    "        print(f\"Minutes: {minutes}\")\n",
    "        print(f\"\\nPick: {side} {line}\")\n",
    "        print(f\"Actual: {actual_value}\")\n",
    "        print(f\"Difference: {actual_value - line:+.1f}\")\n",
    "        print(f\"\\nOutcome: {'WIN' if won else 'LOSS'}\")\n",
    "        print(f\"Profit: {'+0.91' if won else '-1.00'} units\")\n",
    "    else:\n",
    "        print(f\"\\nNo game log found for {real_pick['player_name']} on {real_pick['game_date']}\")\n",
    "        print(\"(Player may have been injured, DNP, or game not yet played)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if real_pick and result:\n",
    "    actual_value, minutes, _ = result\n",
    "    line = real_pick.get('line', real_pick.get('best_line'))\n",
    "    projection = real_pick.get('projection', line)\n",
    "    prob = real_pick.get('probability', 0.5)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Left: Prediction vs Actual\n",
    "    ax1 = axes[0]\n",
    "    categories = ['Line', 'Projection', 'Actual']\n",
    "    values = [line, projection, actual_value]\n",
    "    colors = ['#3498db', '#9b59b6', '#2ecc71' if actual_value > line else '#e74c3c']\n",
    "    \n",
    "    bars = ax1.bar(categories, values, color=colors, edgecolor='black', width=0.6)\n",
    "    ax1.axhline(y=line, color='red', linestyle='--', alpha=0.7, label=f'Line ({line})')\n",
    "    ax1.set_ylabel(f'{real_pick[\"stat_type\"]}')\n",
    "    ax1.set_title(f'{real_pick[\"player_name\"]} - {real_pick[\"game_date\"]}')\n",
    "    ax1.legend()\n",
    "    \n",
    "    for bar, val in zip(bars, values):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, \n",
    "                 f'{val:.1f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Right: Probability gauge\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    # Simple bar representation of probability\n",
    "    ax2.barh(['P(OVER)'], [prob * 100], color='#3498db', height=0.4)\n",
    "    ax2.barh(['P(UNDER)'], [(1-prob) * 100], color='#e74c3c', height=0.4)\n",
    "    ax2.axvline(x=52.4, color='black', linestyle='--', label='Breakeven (52.4%)')\n",
    "    ax2.set_xlim(0, 100)\n",
    "    ax2.set_xlabel('Probability (%)')\n",
    "    ax2.set_title('Model Confidence')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Add text\n",
    "    ax2.text(prob * 100 / 2, 0, f'{prob*100:.1f}%', ha='center', va='center', \n",
    "             fontsize=14, fontweight='bold', color='white')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prediction_example.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Examine Full Pick JSON\n",
    "\n",
    "This is the actual JSON output from our production system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if real_pick:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"FULL PICK JSON (Real Production Output)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(json.dumps(real_pick, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "This notebook demonstrated the complete prediction pipeline with **real data**:\n",
    "\n",
    "1. **Model Loading** - 166 features, two-head LightGBM architecture from `saved_xl/`\n",
    "2. **Real Pick** - Actual production pick from `predictions/` directory\n",
    "3. **Validation** - Outcome verified against PostgreSQL database\n",
    "\n",
    "**In Production:**\n",
    "- Features are extracted from 4 PostgreSQL databases in real-time\n",
    "- Props are fetched from 7 sportsbooks via BettingPros API\n",
    "- Picks are generated twice daily (morning refresh, evening predictions)\n",
    "- Results are tracked and validated automatically\n",
    "\n",
    "**All data shown is REAL** - no synthetic or simulated data was used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
