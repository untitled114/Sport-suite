{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance Analysis\n",
    "\n",
    "This notebook analyzes what drives our NBA player props predictions using:\n",
    "- **LightGBM native importance** (gain, split)\n",
    "- **SHAP values** for interpretable ML\n",
    "- **Feature category analysis** to understand model behavior\n",
    "\n",
    "**Key Question**: Which features most influence whether a player goes OVER their prop line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Optional: SHAP for interpretability\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "    print(\"SHAP not installed. Run: pip install shap\")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Production Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = Path(\"../nba/models/saved_xl\")\n",
    "MARKET = \"points\"  # Change to 'rebounds' to analyze that market\n",
    "\n",
    "# Load model components\n",
    "with open(MODELS_DIR / f\"{MARKET}_market_regressor.pkl\", \"rb\") as f:\n",
    "    regressor = pickle.load(f)\n",
    "\n",
    "with open(MODELS_DIR / f\"{MARKET}_market_classifier.pkl\", \"rb\") as f:\n",
    "    classifier = pickle.load(f)\n",
    "\n",
    "with open(MODELS_DIR / f\"{MARKET}_market_features.pkl\", \"rb\") as f:\n",
    "    feature_names = pickle.load(f)\n",
    "\n",
    "with open(MODELS_DIR / f\"{MARKET}_market_metadata.json\", \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(f\"Market: {MARKET.upper()}\")\n",
    "print(f\"Trained: {metadata['trained_date']}\")\n",
    "print(f\"Features: {len(feature_names)}\")\n",
    "print(f\"Architecture: {metadata['architecture']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LightGBM Native Feature Importance\n",
    "\n",
    "LightGBM provides two importance metrics:\n",
    "- **Gain**: Total gain (reduction in loss) from splits on this feature\n",
    "- **Split**: Number of times this feature was used for splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get importance from both models\n",
    "reg_importance = regressor.feature_importances_\n",
    "clf_importance = classifier.feature_importances_\n",
    "\n",
    "# Create importance DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'regressor_importance': reg_importance,\n",
    "    'classifier_importance': clf_importance\n",
    "})\n",
    "\n",
    "# Combined importance (average of both heads)\n",
    "importance_df['combined'] = (importance_df['regressor_importance'] + \n",
    "                             importance_df['classifier_importance']) / 2\n",
    "\n",
    "importance_df = importance_df.sort_values('combined', ascending=False)\n",
    "importance_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 25 features\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 10))\n",
    "\n",
    "# Regressor importance\n",
    "top_reg = importance_df.nlargest(25, 'regressor_importance')\n",
    "axes[0].barh(top_reg['feature'], top_reg['regressor_importance'], color='steelblue')\n",
    "axes[0].set_xlabel('Importance (Gain)')\n",
    "axes[0].set_title(f'{MARKET.upper()} Regressor - Top 25 Features')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Classifier importance\n",
    "top_clf = importance_df.nlargest(25, 'classifier_importance')\n",
    "axes[1].barh(top_clf['feature'], top_clf['classifier_importance'], color='darkorange')\n",
    "axes[1].set_xlabel('Importance (Gain)')\n",
    "axes[1].set_title(f'{MARKET.upper()} Classifier - Top 25 Features')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance_native.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Category Analysis\n",
    "\n",
    "Group features by category to understand which types of information matter most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_feature(name):\n",
    "    \"\"\"Assign feature to category based on naming convention.\"\"\"\n",
    "    if name.startswith('ema_') or name.startswith('fg_pct') or name.startswith('ft_rate'):\n",
    "        return 'Player Rolling Stats'\n",
    "    elif name.startswith('h2h_'):\n",
    "        return 'Head-to-Head History'\n",
    "    elif name.startswith('prop_'):\n",
    "        return 'Prop History'\n",
    "    elif name.startswith('bp_'):\n",
    "        return 'BettingPros Data'\n",
    "    elif name.startswith('vegas_'):\n",
    "        return 'Vegas Lines'\n",
    "    elif 'deviation' in name or 'line' in name.lower() or 'book' in name:\n",
    "        return 'Book Disagreement'\n",
    "    elif 'team' in name or 'opp' in name or 'pace' in name:\n",
    "        return 'Team Context'\n",
    "    elif 'rest' in name or 'b2b' in name or 'travel' in name or 'game' in name:\n",
    "        return 'Schedule/Game'\n",
    "    elif name in ['is_home', 'expected_diff', 'starter_flag', 'position_encoded']:\n",
    "        return 'Computed'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "importance_df['category'] = importance_df['feature'].apply(categorize_feature)\n",
    "\n",
    "# Aggregate by category\n",
    "category_importance = importance_df.groupby('category').agg({\n",
    "    'combined': 'sum',\n",
    "    'feature': 'count'\n",
    "}).rename(columns={'feature': 'num_features'})\n",
    "\n",
    "category_importance['avg_importance'] = category_importance['combined'] / category_importance['num_features']\n",
    "category_importance = category_importance.sort_values('combined', ascending=False)\n",
    "category_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize category importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Total importance by category\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, len(category_importance)))\n",
    "axes[0].barh(category_importance.index, category_importance['combined'], color=colors)\n",
    "axes[0].set_xlabel('Total Importance')\n",
    "axes[0].set_title('Total Feature Importance by Category')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Pie chart of importance distribution\n",
    "axes[1].pie(category_importance['combined'], labels=category_importance.index, \n",
    "            autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "axes[1].set_title('Importance Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_category_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SHAP Analysis (if available)\n",
    "\n",
    "SHAP values provide interpretable, additive feature attributions that explain individual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP_AVAILABLE:\n",
    "    # Load sample data for SHAP analysis\n",
    "    # Using validation data as background\n",
    "    sample_data_path = Path(\"../nba/features/datasets\")\n",
    "    \n",
    "    # Try to load training data for background distribution\n",
    "    try:\n",
    "        training_file = list(sample_data_path.glob(f\"*{MARKET.upper()}*.csv\"))[0]\n",
    "        df = pd.read_csv(training_file, nrows=1000)  # Sample for speed\n",
    "        \n",
    "        # Get feature columns only\n",
    "        X = df[feature_names].values\n",
    "        \n",
    "        print(f\"Loaded {len(X)} samples for SHAP analysis\")\n",
    "        print(f\"Computing SHAP values (this may take a minute)...\")\n",
    "        \n",
    "        # Create SHAP explainer\n",
    "        explainer = shap.TreeExplainer(classifier)\n",
    "        shap_values = explainer.shap_values(X[:200])  # Subset for speed\n",
    "        \n",
    "        print(\"SHAP values computed!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load training data: {e}\")\n",
    "        SHAP_AVAILABLE = False\n",
    "else:\n",
    "    print(\"SHAP not available. Install with: pip install shap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP_AVAILABLE and 'shap_values' in dir():\n",
    "    # SHAP summary plot\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    shap.summary_plot(shap_values[1] if isinstance(shap_values, list) else shap_values, \n",
    "                      X[:200], \n",
    "                      feature_names=feature_names,\n",
    "                      max_display=25,\n",
    "                      show=False)\n",
    "    plt.title(f'{MARKET.upper()} Classifier - SHAP Summary')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('shap_summary.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP_AVAILABLE and 'shap_values' in dir():\n",
    "    # SHAP bar plot (mean absolute SHAP values)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    shap.summary_plot(shap_values[1] if isinstance(shap_values, list) else shap_values, \n",
    "                      X[:200], \n",
    "                      feature_names=feature_names,\n",
    "                      plot_type='bar',\n",
    "                      max_display=25,\n",
    "                      show=False)\n",
    "    plt.title(f'{MARKET.upper()} - Mean |SHAP| Values')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('shap_bar.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Key Insights\n",
    "\n",
    "### Top Predictive Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(f\"TOP 15 MOST IMPORTANT FEATURES - {MARKET.upper()} MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, row in importance_df.head(15).iterrows():\n",
    "    print(f\"{importance_df.head(15).index.get_loc(i)+1:2d}. {row['feature']:40s} ({row['category']})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CATEGORY RANKING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for cat, row in category_importance.iterrows():\n",
    "    pct = row['combined'] / category_importance['combined'].sum() * 100\n",
    "    print(f\"{cat:25s}: {pct:5.1f}% ({int(row['num_features']):3d} features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interpretation\n",
    "\n",
    "### What This Tells Us About the Model\n",
    "\n",
    "1. **`expected_diff` dominates** - The difference between predicted value and line is the strongest predictor. This validates our two-head architecture: the regressor's prediction minus the line creates a powerful signal.\n",
    "\n",
    "2. **Recent performance matters** - EMA rolling stats (L3, L5) rank highly, showing the model weights recent games appropriately.\n",
    "\n",
    "3. **Book disagreement is valuable** - Line spread and book deviations contribute significantly, validating our multi-source line shopping approach.\n",
    "\n",
    "4. **Head-to-head history helps** - H2H features rank in the top categories, confirming that matchup-specific performance is predictive.\n",
    "\n",
    "5. **Prop history provides edge** - Bayesian hit rates and historical patterns contribute to predictions.\n",
    "\n",
    "### Actionable Insights\n",
    "\n",
    "- **Trust high `expected_diff`**: When the model predicts significantly above/below line, confidence is warranted\n",
    "- **Line spread matters**: Props with disagreement between books (high spread) have more predictable outcomes\n",
    "- **Recent form > season averages**: L3/L5 stats are more predictive than L20 stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
